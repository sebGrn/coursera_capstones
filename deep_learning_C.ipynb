{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "# Get the dataset"}, {"metadata": {}, "cell_type": "code", "source": "import pandas as pd\nimport numpy as np", "execution_count": 1, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "concrete_data = pd.read_csv('https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0101EN/labs/data/concrete_data.csv')\nconcrete_data.head()", "execution_count": 2, "outputs": [{"output_type": "execute_result", "execution_count": 2, "data": {"text/plain": "   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n0   540.0                 0.0      0.0  162.0               2.5   \n1   540.0                 0.0      0.0  162.0               2.5   \n2   332.5               142.5      0.0  228.0               0.0   \n3   332.5               142.5      0.0  228.0               0.0   \n4   198.6               132.4      0.0  192.0               0.0   \n\n   Coarse Aggregate  Fine Aggregate  Age  Strength  \n0            1040.0           676.0   28     79.99  \n1            1055.0           676.0   28     61.89  \n2             932.0           594.0  270     40.27  \n3             932.0           594.0  365     41.05  \n4             978.4           825.5  360     44.30  ", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Cement</th>\n      <th>Blast Furnace Slag</th>\n      <th>Fly Ash</th>\n      <th>Water</th>\n      <th>Superplasticizer</th>\n      <th>Coarse Aggregate</th>\n      <th>Fine Aggregate</th>\n      <th>Age</th>\n      <th>Strength</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>540.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>162.0</td>\n      <td>2.5</td>\n      <td>1040.0</td>\n      <td>676.0</td>\n      <td>28</td>\n      <td>79.99</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>540.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>162.0</td>\n      <td>2.5</td>\n      <td>1055.0</td>\n      <td>676.0</td>\n      <td>28</td>\n      <td>61.89</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>332.5</td>\n      <td>142.5</td>\n      <td>0.0</td>\n      <td>228.0</td>\n      <td>0.0</td>\n      <td>932.0</td>\n      <td>594.0</td>\n      <td>270</td>\n      <td>40.27</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>332.5</td>\n      <td>142.5</td>\n      <td>0.0</td>\n      <td>228.0</td>\n      <td>0.0</td>\n      <td>932.0</td>\n      <td>594.0</td>\n      <td>365</td>\n      <td>41.05</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>198.6</td>\n      <td>132.4</td>\n      <td>0.0</td>\n      <td>192.0</td>\n      <td>0.0</td>\n      <td>978.4</td>\n      <td>825.5</td>\n      <td>360</td>\n      <td>44.30</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "concrete_data_columns = concrete_data.columns\n\npredictors = concrete_data[concrete_data_columns[concrete_data_columns != 'Strength']] # all columns except Strength\ntarget = concrete_data['Strength'] # Strength column", "execution_count": 3, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "predictors.head()", "execution_count": 4, "outputs": [{"output_type": "execute_result", "execution_count": 4, "data": {"text/plain": "   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n0   540.0                 0.0      0.0  162.0               2.5   \n1   540.0                 0.0      0.0  162.0               2.5   \n2   332.5               142.5      0.0  228.0               0.0   \n3   332.5               142.5      0.0  228.0               0.0   \n4   198.6               132.4      0.0  192.0               0.0   \n\n   Coarse Aggregate  Fine Aggregate  Age  \n0            1040.0           676.0   28  \n1            1055.0           676.0   28  \n2             932.0           594.0  270  \n3             932.0           594.0  365  \n4             978.4           825.5  360  ", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Cement</th>\n      <th>Blast Furnace Slag</th>\n      <th>Fly Ash</th>\n      <th>Water</th>\n      <th>Superplasticizer</th>\n      <th>Coarse Aggregate</th>\n      <th>Fine Aggregate</th>\n      <th>Age</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>540.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>162.0</td>\n      <td>2.5</td>\n      <td>1040.0</td>\n      <td>676.0</td>\n      <td>28</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>540.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>162.0</td>\n      <td>2.5</td>\n      <td>1055.0</td>\n      <td>676.0</td>\n      <td>28</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>332.5</td>\n      <td>142.5</td>\n      <td>0.0</td>\n      <td>228.0</td>\n      <td>0.0</td>\n      <td>932.0</td>\n      <td>594.0</td>\n      <td>270</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>332.5</td>\n      <td>142.5</td>\n      <td>0.0</td>\n      <td>228.0</td>\n      <td>0.0</td>\n      <td>932.0</td>\n      <td>594.0</td>\n      <td>365</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>198.6</td>\n      <td>132.4</td>\n      <td>0.0</td>\n      <td>192.0</td>\n      <td>0.0</td>\n      <td>978.4</td>\n      <td>825.5</td>\n      <td>360</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "# number of predictors\nn_cols = predictors.shape[1]", "execution_count": 5, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "target.head()", "execution_count": 6, "outputs": [{"output_type": "execute_result", "execution_count": 6, "data": {"text/plain": "0    79.99\n1    61.89\n2    40.27\n3    41.05\n4    44.30\nName: Strength, dtype: float64"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "# normalize the data\n# subtracting the mean from the individual predictors and dividing by the standard deviation\npredictors_norm = (predictors - predictors.mean()) / predictors.std()\npredictors_norm.head()", "execution_count": 7, "outputs": [{"output_type": "execute_result", "execution_count": 7, "data": {"text/plain": "     Cement  Blast Furnace Slag   Fly Ash     Water  Superplasticizer  \\\n0  2.476712           -0.856472 -0.846733 -0.916319         -0.620147   \n1  2.476712           -0.856472 -0.846733 -0.916319         -0.620147   \n2  0.491187            0.795140 -0.846733  2.174405         -1.038638   \n3  0.491187            0.795140 -0.846733  2.174405         -1.038638   \n4 -0.790075            0.678079 -0.846733  0.488555         -1.038638   \n\n   Coarse Aggregate  Fine Aggregate       Age  \n0          0.862735       -1.217079 -0.279597  \n1          1.055651       -1.217079 -0.279597  \n2         -0.526262       -2.239829  3.551340  \n3         -0.526262       -2.239829  5.055221  \n4          0.070492        0.647569  4.976069  ", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Cement</th>\n      <th>Blast Furnace Slag</th>\n      <th>Fly Ash</th>\n      <th>Water</th>\n      <th>Superplasticizer</th>\n      <th>Coarse Aggregate</th>\n      <th>Fine Aggregate</th>\n      <th>Age</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2.476712</td>\n      <td>-0.856472</td>\n      <td>-0.846733</td>\n      <td>-0.916319</td>\n      <td>-0.620147</td>\n      <td>0.862735</td>\n      <td>-1.217079</td>\n      <td>-0.279597</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2.476712</td>\n      <td>-0.856472</td>\n      <td>-0.846733</td>\n      <td>-0.916319</td>\n      <td>-0.620147</td>\n      <td>1.055651</td>\n      <td>-1.217079</td>\n      <td>-0.279597</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.491187</td>\n      <td>0.795140</td>\n      <td>-0.846733</td>\n      <td>2.174405</td>\n      <td>-1.038638</td>\n      <td>-0.526262</td>\n      <td>-2.239829</td>\n      <td>3.551340</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.491187</td>\n      <td>0.795140</td>\n      <td>-0.846733</td>\n      <td>2.174405</td>\n      <td>-1.038638</td>\n      <td>-0.526262</td>\n      <td>-2.239829</td>\n      <td>5.055221</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.790075</td>\n      <td>0.678079</td>\n      <td>-0.846733</td>\n      <td>0.488555</td>\n      <td>-1.038638</td>\n      <td>0.070492</td>\n      <td>0.647569</td>\n      <td>4.976069</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "# Build neural network\n\nUse the Keras library to build a neural network with the following:\n- One hidden layer of 10 nodes, and a ReLU activation function\n- Use the adam optimizer and the mean squared error  as the loss function"}, {"metadata": {}, "cell_type": "code", "source": "import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers", "execution_count": 8, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# build a model for regression with one hidden layer of 10 nodes, and a ReLU activation function\nmodel = keras.Sequential()\nmodel.add(layers.Dense(10, activation='relu', input_shape=(n_cols,)))\nmodel.add(layers.Dense(1))\nmodel.compile(optimizer='adam', loss='mean_squared_error')", "execution_count": 9, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\n\ndef train_model(mse_list):\n    # 1. Randomly split the data into a training and test sets by holding 30% of the data for testing. You can use the train_test_split helper function from Scikit-learn.\n    X_train, X_test, y_train, y_test = train_test_split(predictors_norm, target, test_size=0.3)\n    # 2. Train the model on the training data using 50 epochs.    \n    model.fit(X_train, y_train, epochs=100, verbose=0)    \n    # 3. Evaluate the model on the test data and compute the mean squared error between the predicted concrete strength and the actual concrete strength. You can use the mean_squared_error function from Scikit-learn.\n    loss_val  = model.evaluate(X_test, y_test)\n    print(\"test loss, test acc:\", loss_val)\n    y_pred = model.predict(X_test)\n    mse = mean_squared_error(y_test, y_pred)\n    print(\"mean squared error:\", mse)\n    mse_list.append(mse)", "execution_count": 10, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# 4. Repeat steps 1 - 3, 50 times, i.e., create a list of 50 mean squared errors\nmse_list = []\nfor i in range(0, 50):\n    train_model(mse_list)   ", "execution_count": 11, "outputs": [{"output_type": "stream", "text": "10/10 [==============================] - 0s 951us/step - loss: 161.5930\ntest loss, test acc: 161.593017578125\nmean squared error: 161.59300361521784\n10/10 [==============================] - 0s 1ms/step - loss: 111.5178\ntest loss, test acc: 111.517822265625\nmean squared error: 111.517821307157\n10/10 [==============================] - 0s 1ms/step - loss: 115.0772\ntest loss, test acc: 115.07721710205078\nmean squared error: 115.07721048153871\n10/10 [==============================] - 0s 1ms/step - loss: 104.8837\ntest loss, test acc: 104.88371276855469\nmean squared error: 104.88371805568694\n10/10 [==============================] - 0s 1ms/step - loss: 100.5305\ntest loss, test acc: 100.53052520751953\nmean squared error: 100.53052664337683\n10/10 [==============================] - 0s 1ms/step - loss: 107.9453\ntest loss, test acc: 107.94532775878906\nmean squared error: 107.945330522696\n10/10 [==============================] - 0s 1ms/step - loss: 109.9388\ntest loss, test acc: 109.93882751464844\nmean squared error: 109.93882349871201\n10/10 [==============================] - 0s 1ms/step - loss: 105.5287\ntest loss, test acc: 105.5286865234375\nmean squared error: 105.5286921478799\n10/10 [==============================] - 0s 1ms/step - loss: 92.8766\ntest loss, test acc: 92.87660217285156\nmean squared error: 92.87660688479428\n10/10 [==============================] - 0s 987us/step - loss: 99.0997\ntest loss, test acc: 99.09972381591797\nmean squared error: 99.09972568292433\n10/10 [==============================] - 0s 1ms/step - loss: 103.2936\ntest loss, test acc: 103.29356384277344\nmean squared error: 103.29355859972674\n10/10 [==============================] - 0s 1ms/step - loss: 106.6519\ntest loss, test acc: 106.65186309814453\nmean squared error: 106.65186381905433\n10/10 [==============================] - 0s 1ms/step - loss: 115.6416\ntest loss, test acc: 115.64164733886719\nmean squared error: 115.64164067770078\n10/10 [==============================] - 0s 1ms/step - loss: 95.6923\ntest loss, test acc: 95.69229125976562\nmean squared error: 95.69229445582309\n10/10 [==============================] - 0s 934us/step - loss: 111.2981\ntest loss, test acc: 111.29811096191406\nmean squared error: 111.29811789409365\n10/10 [==============================] - 0s 1ms/step - loss: 120.2720\ntest loss, test acc: 120.27201843261719\nmean squared error: 120.27201168547113\n10/10 [==============================] - 0s 1ms/step - loss: 110.8877\ntest loss, test acc: 110.88774108886719\nmean squared error: 110.88773325643896\n10/10 [==============================] - 0s 948us/step - loss: 115.9958\ntest loss, test acc: 115.9957504272461\nmean squared error: 115.99574612885058\n10/10 [==============================] - 0s 952us/step - loss: 98.7448\ntest loss, test acc: 98.74481964111328\nmean squared error: 98.74481046218109\n10/10 [==============================] - 0s 890us/step - loss: 101.8816\ntest loss, test acc: 101.88158416748047\nmean squared error: 101.88158101449463\n10/10 [==============================] - 0s 1ms/step - loss: 115.6027\ntest loss, test acc: 115.60271453857422\nmean squared error: 115.60270643823986\n10/10 [==============================] - 0s 1ms/step - loss: 99.2640\ntest loss, test acc: 99.26398468017578\nmean squared error: 99.26398095260794\n10/10 [==============================] - 0s 1ms/step - loss: 105.1483\ntest loss, test acc: 105.14827728271484\nmean squared error: 105.14828178609149\n10/10 [==============================] - 0s 1ms/step - loss: 102.5999\ntest loss, test acc: 102.59989166259766\nmean squared error: 102.59988560917321\n10/10 [==============================] - 0s 946us/step - loss: 111.9354\ntest loss, test acc: 111.9354248046875\nmean squared error: 111.93542129323129\n10/10 [==============================] - 0s 1ms/step - loss: 103.6056\ntest loss, test acc: 103.60564422607422\nmean squared error: 103.6056426381211\n10/10 [==============================] - 0s 1ms/step - loss: 107.0725\ntest loss, test acc: 107.07247161865234\nmean squared error: 107.07247062422933\n10/10 [==============================] - 0s 1ms/step - loss: 118.1272\ntest loss, test acc: 118.1271743774414\nmean squared error: 118.12715969032224\n10/10 [==============================] - 0s 1ms/step - loss: 114.1737\ntest loss, test acc: 114.17369842529297\nmean squared error: 114.17370753354638\n10/10 [==============================] - 0s 948us/step - loss: 102.5755\ntest loss, test acc: 102.57550811767578\nmean squared error: 102.57551052986064\n10/10 [==============================] - 0s 998us/step - loss: 102.8132\ntest loss, test acc: 102.81324005126953\nmean squared error: 102.81324314330988\n10/10 [==============================] - 0s 983us/step - loss: 110.6205\ntest loss, test acc: 110.6204833984375\nmean squared error: 110.62049716307737\n10/10 [==============================] - 0s 1ms/step - loss: 108.6523\ntest loss, test acc: 108.65232849121094\nmean squared error: 108.65232875643848\n10/10 [==============================] - 0s 1ms/step - loss: 106.3134\ntest loss, test acc: 106.31344604492188\nmean squared error: 106.31345172624059\n10/10 [==============================] - 0s 1ms/step - loss: 106.4818\ntest loss, test acc: 106.48175811767578\nmean squared error: 106.48175596927364\n10/10 [==============================] - 0s 1ms/step - loss: 104.8242\ntest loss, test acc: 104.8241958618164\nmean squared error: 104.82419407435702\n10/10 [==============================] - 0s 959us/step - loss: 87.5895\ntest loss, test acc: 87.5894546508789\nmean squared error: 87.5894437996949\n10/10 [==============================] - 0s 1ms/step - loss: 91.0136\ntest loss, test acc: 91.01358795166016\nmean squared error: 91.013584824495\n10/10 [==============================] - 0s 1ms/step - loss: 106.4529\ntest loss, test acc: 106.45293426513672\nmean squared error: 106.45292445155924\n10/10 [==============================] - 0s 942us/step - loss: 100.4664\ntest loss, test acc: 100.46638488769531\nmean squared error: 100.46639350882933\n10/10 [==============================] - 0s 1ms/step - loss: 109.9861\ntest loss, test acc: 109.9861068725586\nmean squared error: 109.98610152384524\n10/10 [==============================] - 0s 906us/step - loss: 90.4148\ntest loss, test acc: 90.41484832763672\nmean squared error: 90.41483611405047\n10/10 [==============================] - 0s 1ms/step - loss: 102.1402\ntest loss, test acc: 102.14020538330078\nmean squared error: 102.14021449974067\n10/10 [==============================] - 0s 979us/step - loss: 106.0128\ntest loss, test acc: 106.0128173828125\nmean squared error: 106.01281331990818\n10/10 [==============================] - 0s 1ms/step - loss: 110.1946\ntest loss, test acc: 110.194580078125\nmean squared error: 110.19458748735994\n10/10 [==============================] - 0s 965us/step - loss: 117.9642\ntest loss, test acc: 117.96419525146484\nmean squared error: 117.96419788765081\n10/10 [==============================] - 0s 983us/step - loss: 102.7861\ntest loss, test acc: 102.7861328125\nmean squared error: 102.78612859956532\n10/10 [==============================] - 0s 935us/step - loss: 99.9710\ntest loss, test acc: 99.97101593017578\nmean squared error: 99.97100458868734\n10/10 [==============================] - 0s 1ms/step - loss: 106.4770\ntest loss, test acc: 106.4769515991211\nmean squared error: 106.4769459338801\n10/10 [==============================] - 0s 941us/step - loss: 100.4754\ntest loss, test acc: 100.47538757324219\nmean squared error: 100.47538639618283\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "# 5. Report the mean and the standard deviation of the mean squared errors\n\nimport statistics\n\nprint(\"mse mean:\", statistics.mean(mse_list))\nprint(\"standard deviation:\", statistics.stdev(mse_list))", "execution_count": 12, "outputs": [{"output_type": "stream", "text": "mse mean: 106.82211235394777\nstandard deviation: 10.725070908340987\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.8", "language": "python"}, "language_info": {"name": "python", "version": "3.8.11", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}